{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1mWoIyVGKNZQhcuPGmrpoWniJRP_ba7lE",
      "authorship_tag": "ABX9TyPWr5ss2u5sqCciZoPrsl6k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6705d799d86c4fbdb9bd1789144033fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_695d27952e2d43ee994210431d558482",
              "IPY_MODEL_3457058518d64f07aa8728b104b160ff",
              "IPY_MODEL_e23d32e8f12a4925b938fdae9507d67f"
            ],
            "layout": "IPY_MODEL_6a8a38ca62d640c7a17cddebce49865f"
          }
        },
        "695d27952e2d43ee994210431d558482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb69e1a2a6b41109c5a6cddbaa13663",
            "placeholder": "​",
            "style": "IPY_MODEL_51492ad407f44e32b1feaa953d70f981",
            "value": "Map: 100%"
          }
        },
        "3457058518d64f07aa8728b104b160ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97fd9b33593a42d4a8d6949b1a9164f7",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e28d8a081bcc4a90a74faf2be7f0e76a",
            "value": 16
          }
        },
        "e23d32e8f12a4925b938fdae9507d67f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c2d422a6b34be5b1bc15375d3fbbc9",
            "placeholder": "​",
            "style": "IPY_MODEL_b9a44f0717a549abb2512692d38ce4d0",
            "value": " 16/16 [00:00&lt;00:00, 220.23 examples/s]"
          }
        },
        "6a8a38ca62d640c7a17cddebce49865f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb69e1a2a6b41109c5a6cddbaa13663": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51492ad407f44e32b1feaa953d70f981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fd9b33593a42d4a8d6949b1a9164f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e28d8a081bcc4a90a74faf2be7f0e76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c4c2d422a6b34be5b1bc15375d3fbbc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9a44f0717a549abb2512692d38ce4d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thambara-20/spm-planbot/blob/main/PlanBot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ksDog4eneSL5",
        "outputId": "d9d44180-3245-469e-9552-38e99bbbe2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load dataset from the local Colab path\n",
        "with open('/content/scrum_activities.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "# Convert flattened data to a Hugging Face dataset format\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hgHXYOrMeiVR",
        "outputId": "6c5d62ad-74bd-43fc-bfc7-1c54da634b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['activity', 'input_text', 'output_text'],\n",
            "    num_rows: 16\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2-medium\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Define the tokenize function for each input-output pair\n",
        "def tokenize_function(example):\n",
        "    prompt = example[\"input_text\"] + tokenizer.eos_token  # Add end-of-sequence token to input\n",
        "    target = example[\"output_text\"] + tokenizer.eos_token  # Add end-of-sequence token to output\n",
        "\n",
        "    print(\"prompt:\", prompt)\n",
        "    print(\"target\", target)\n",
        "    # Tokenize prompt and target\n",
        "    input_ids = tokenizer(prompt, truncation=True, padding='max_length', max_length=128)[\"input_ids\"]\n",
        "    target_ids = tokenizer(target, truncation=True, padding='max_length', max_length=128)[\"input_ids\"]\n",
        "\n",
        "    # Prepare labels for training (mask padding tokens to -100)\n",
        "    labels = [-100 if token == tokenizer.pad_token_id else token for token in target_ids]\n",
        "\n",
        "    return {\"input_ids\": input_ids, \"labels\": labels}\n",
        "\n",
        "# Apply tokenizer to the dataset\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 624,
          "referenced_widgets": [
            "6705d799d86c4fbdb9bd1789144033fd",
            "695d27952e2d43ee994210431d558482",
            "3457058518d64f07aa8728b104b160ff",
            "e23d32e8f12a4925b938fdae9507d67f",
            "6a8a38ca62d640c7a17cddebce49865f",
            "4fb69e1a2a6b41109c5a6cddbaa13663",
            "51492ad407f44e32b1feaa953d70f981",
            "97fd9b33593a42d4a8d6949b1a9164f7",
            "e28d8a081bcc4a90a74faf2be7f0e76a",
            "c4c2d422a6b34be5b1bc15375d3fbbc9",
            "b9a44f0717a549abb2512692d38ce4d0"
          ]
        },
        "id": "W_ZMrhBuuLIR",
        "outputId": "e3427590-1635-4964-c5a1-bdbdfdc87d9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6705d799d86c4fbdb9bd1789144033fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prompt: Help me plan tasks for the sprint focused on login features.<|endoftext|>\n",
            "target To plan for login features, break down tasks like implementing the authentication API, designing the login UI, and integrating UI with the backend. Prioritize based on dependencies.<|endoftext|>\n",
            "prompt: How should we prioritize tasks in sprint planning?<|endoftext|>\n",
            "target Start by prioritizing tasks that provide the most value to the end user, and consider dependencies. High-impact tasks with fewer dependencies should be prioritized.<|endoftext|>\n",
            "prompt: What should I share in today's stand-up?<|endoftext|>\n",
            "target In your stand-up update, share what you completed yesterday, any blockers, and what you plan to work on today. Keep it brief and focused.<|endoftext|>\n",
            "prompt: I'm blocked on a task due to missing permissions. What should I do?<|endoftext|>\n",
            "target Mention this blocker in the stand-up so your team or manager can assist in resolving it. If urgent, reach out to the appropriate person directly.<|endoftext|>\n",
            "prompt: How do I prioritize backlog items during refinement?<|endoftext|>\n",
            "target Consider each item's value to the user and readiness. Focus on high-priority items that are ready for development and will bring noticeable improvement.<|endoftext|>\n",
            "prompt: What questions should I ask during backlog refinement?<|endoftext|>\n",
            "target Ask questions to clarify requirements, dependencies, and acceptance criteria. Ensure each item is well-defined and prioritized appropriately.<|endoftext|>\n",
            "prompt: What should I discuss in the retrospective?<|endoftext|>\n",
            "target In the retrospective, discuss what went well, what could be improved, and any lessons learned. Set actionable goals for the next sprint.<|endoftext|>\n",
            "prompt: How can we improve our communication based on last sprint's challenges?<|endoftext|>\n",
            "target Consider implementing more regular check-ins, updating task status frequently, and ensuring clear documentation to improve communication.<|endoftext|>\n",
            "prompt: How should I approach task estimation for the team?<|endoftext|>\n",
            "target Use story points to estimate the complexity. Small tasks might be 1-3 points, medium tasks 5 points, and larger tasks 8 points or more.<|endoftext|>\n",
            "prompt: What's the best way to handle uncertainty during task estimation?<|endoftext|>\n",
            "target If uncertain, assign a broader range or estimate conservatively. You can also break down the task further to gain clarity on the complexity.<|endoftext|>\n",
            "prompt: What should I focus on for the sprint review?<|endoftext|>\n",
            "target Highlight the completed features, demonstrate them if possible, and discuss any feedback or unmet goals to help plan for the next sprint.<|endoftext|>\n",
            "prompt: How can I structure my sprint review presentation?<|endoftext|>\n",
            "target Start with an overview of sprint goals, demonstrate key features completed, discuss any challenges faced, and finish with next steps or improvements.<|endoftext|>\n",
            "prompt: How do I create an effective user story?<|endoftext|>\n",
            "target Write a user story that describes the who, what, and why of the feature. Example: 'As a user, I want to log in securely so that my data is protected.'<|endoftext|>\n",
            "prompt: What are the essential parts of a user story?<|endoftext|>\n",
            "target A user story should include a role, goal, and reason. For example: 'As [role], I want [goal] so that [reason].' Add acceptance criteria for clarity.<|endoftext|>\n",
            "prompt: How should I prioritize defects?<|endoftext|>\n",
            "target Prioritize defects based on severity and impact on the user. Critical bugs that block functionality should be addressed first.<|endoftext|>\n",
            "prompt: What should I include in a defect report?<|endoftext|>\n",
            "target Include a clear description of the issue, steps to reproduce, expected vs. actual results, and any relevant screenshots or logs.<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/gpt2_sprint_model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=2,\n",
        "    save_steps=500,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='/content/logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "dvZFZWqmgbcV",
        "outputId": "4932ad45-df78-48b8-8ee2-69b46d3d5830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='80' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [80/80 01:21, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=80, training_loss=0.5449258804321289, metrics={'train_runtime': 81.6066, 'train_samples_per_second': 1.961, 'train_steps_per_second': 0.98, 'total_flos': 37148027781120.0, 'train_loss': 0.5449258804321289, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/gpt2_sprint_model\")\n",
        "tokenizer.save_pretrained(\"/content/gpt2_sprint_model\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSTd-dikrm3",
        "outputId": "4f5023ba-1a7e-4a61-b6f7-d2395b197d7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gpt2_sprint_model/tokenizer_config.json',\n",
              " '/content/gpt2_sprint_model/special_tokens_map.json',\n",
              " '/content/gpt2_sprint_model/vocab.json',\n",
              " '/content/gpt2_sprint_model/merges.txt',\n",
              " '/content/gpt2_sprint_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the trained model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/gpt2_sprint_model\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"/content/gpt2_sprint_model\")\n",
        "\n",
        "# Set up the pipeline for text generation on GPU if available\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)  # use device=0 for GPU\n",
        "\n",
        "# Generate output for a test input\n",
        "input_text = \"Help me plan tasks for the sprint focused on login features.\"\n",
        "output = generator(input_text, max_length=100, num_return_sequences=1, truncation=True)\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4FQeLs6saS4",
        "outputId": "0c5285ba-553d-4a6d-ae84-75514661d712"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me plan tasks for the sprint focused on login features. What should I focus on for the sprint? What should I share in today's sprint retrospective?\n",
            "\n",
            "During the sprint planning stage, we prioritize the tasks that we should take on based on our sprint goals. How should we prioritize tasks during refinement? What should we share in today's sprint retrospective?\n",
            "\n",
            "Once we've identified the areas we should prioritize during refinement, we share that information with the sprint team. What should we discuss during\n"
          ]
        }
      ]
    }
  ]
}