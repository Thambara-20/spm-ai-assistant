{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1mWoIyVGKNZQhcuPGmrpoWniJRP_ba7lE",
      "authorship_tag": "ABX9TyNdB8N5FBb1009Ko+GmS9CF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbadb9becc72408f80ba94f8f85769f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b13b9a1e18e4457abfa57159fd54e42",
              "IPY_MODEL_b984fb842a584729a8bffce4b9174b07",
              "IPY_MODEL_a02a4123a75f40febbf0d081f83ce992"
            ],
            "layout": "IPY_MODEL_d33cb04fcb574df281b45f1e04244c1f"
          }
        },
        "9b13b9a1e18e4457abfa57159fd54e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3c16ebecd7143978a4955a4ea645eff",
            "placeholder": "​",
            "style": "IPY_MODEL_21a2af457ec74f83a6f0258e93ec67cf",
            "value": "Map: 100%"
          }
        },
        "b984fb842a584729a8bffce4b9174b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcb4a375a15e48b7b6c47a71b72e3753",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_25d5e7dfa76c46a9ba9054f68cc5e953",
            "value": 16
          }
        },
        "a02a4123a75f40febbf0d081f83ce992": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e3d9929935542f3ba4e0787081f048a",
            "placeholder": "​",
            "style": "IPY_MODEL_40686dc6a3334ea3903c2b04eb8346ee",
            "value": " 16/16 [00:00&lt;00:00, 46.16 examples/s]"
          }
        },
        "d33cb04fcb574df281b45f1e04244c1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3c16ebecd7143978a4955a4ea645eff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21a2af457ec74f83a6f0258e93ec67cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fcb4a375a15e48b7b6c47a71b72e3753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d5e7dfa76c46a9ba9054f68cc5e953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e3d9929935542f3ba4e0787081f048a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40686dc6a3334ea3903c2b04eb8346ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Thambara-20/spm-ai-assistant/blob/main/spm_ai_assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch datasets\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ksDog4eneSL5",
        "outputId": "d9d44180-3245-469e-9552-38e99bbbe2b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# Load dataset from the local Colab path\n",
        "with open('/content/scrum_activities.json') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "dataset = Dataset.from_list(data)\n",
        "\n",
        "# Convert flattened data to a Hugging Face dataset format\n",
        "print(dataset)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hgHXYOrMeiVR",
        "outputId": "8df9b869-3d78-4e1c-de5f-7a19929a1c16"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['activity', 'input_text', 'output_text'],\n",
            "    num_rows: 16\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
        "\n",
        "model_name = \"gpt2-medium\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "# Define the tokenize function for each input-output pair\n",
        "def tokenize_function(example):\n",
        "    prompt = example[\"input_text\"] + tokenizer.eos_token  # Add end-of-sequence token to input\n",
        "    target = example[\"output_text\"] + tokenizer.eos_token  # Add end-of-sequence token to output\n",
        "\n",
        "    print(\"activity:\", example[\"activity\"])\n",
        "    print(\"prompt:\", prompt)\n",
        "    print(\"target:\", target)\n",
        "\n",
        "    input_ids = tokenizer(prompt, truncation=True, padding='max_length', max_length=128)[\"input_ids\"]\n",
        "    target_ids = tokenizer(target, truncation=True, padding='max_length', max_length=128)[\"input_ids\"]\n",
        "\n",
        "    # Prepare labels for training (mask padding tokens to -100)\n",
        "    labels = [-100 if token == tokenizer.pad_token_id else token for token in target_ids]\n",
        "\n",
        "    return {\n",
        "        \"activity\": example[\"activity\"],  # Include activity in the output\n",
        "        \"input_ids\": input_ids,\n",
        "        \"labels\": labels\n",
        "    }\n",
        "\n",
        "# Apply tokenizer to the dataset\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 937,
          "referenced_widgets": [
            "cbadb9becc72408f80ba94f8f85769f5",
            "9b13b9a1e18e4457abfa57159fd54e42",
            "b984fb842a584729a8bffce4b9174b07",
            "a02a4123a75f40febbf0d081f83ce992",
            "d33cb04fcb574df281b45f1e04244c1f",
            "a3c16ebecd7143978a4955a4ea645eff",
            "21a2af457ec74f83a6f0258e93ec67cf",
            "fcb4a375a15e48b7b6c47a71b72e3753",
            "25d5e7dfa76c46a9ba9054f68cc5e953",
            "1e3d9929935542f3ba4e0787081f048a",
            "40686dc6a3334ea3903c2b04eb8346ee"
          ]
        },
        "id": "W_ZMrhBuuLIR",
        "outputId": "05636d5b-fcda-4ec0-9670-38abb3277d6e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/16 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbadb9becc72408f80ba94f8f85769f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "activity: Sprint Planning\n",
            "prompt: Help me plan tasks for the sprint focused on login features.<|endoftext|>\n",
            "target: To plan for login features, break down tasks like implementing the authentication API, designing the login UI, and integrating UI with the backend. Prioritize based on dependencies.<|endoftext|>\n",
            "activity: Sprint Planning\n",
            "prompt: How should we prioritize tasks in sprint planning?<|endoftext|>\n",
            "target: Start by prioritizing tasks that provide the most value to the end user, and consider dependencies. High-impact tasks with fewer dependencies should be prioritized.<|endoftext|>\n",
            "activity: Daily Stand-up\n",
            "prompt: What should I share in today's stand-up?<|endoftext|>\n",
            "target: In your stand-up update, share what you completed yesterday, any blockers, and what you plan to work on today. Keep it brief and focused.<|endoftext|>\n",
            "activity: Daily Stand-up\n",
            "prompt: I'm blocked on a task due to missing permissions. What should I do?<|endoftext|>\n",
            "target: Mention this blocker in the stand-up so your team or manager can assist in resolving it. If urgent, reach out to the appropriate person directly.<|endoftext|>\n",
            "activity: Backlog Refinement\n",
            "prompt: How do I prioritize backlog items during refinement?<|endoftext|>\n",
            "target: Consider each item's value to the user and readiness. Focus on high-priority items that are ready for development and will bring noticeable improvement.<|endoftext|>\n",
            "activity: Backlog Refinement\n",
            "prompt: What questions should I ask during backlog refinement?<|endoftext|>\n",
            "target: Ask questions to clarify requirements, dependencies, and acceptance criteria. Ensure each item is well-defined and prioritized appropriately.<|endoftext|>\n",
            "activity: Sprint Retrospective\n",
            "prompt: What should I discuss in the retrospective?<|endoftext|>\n",
            "target: In the retrospective, discuss what went well, what could be improved, and any lessons learned. Set actionable goals for the next sprint.<|endoftext|>\n",
            "activity: Sprint Retrospective\n",
            "prompt: How can we improve our communication based on last sprint's challenges?<|endoftext|>\n",
            "target: Consider implementing more regular check-ins, updating task status frequently, and ensuring clear documentation to improve communication.<|endoftext|>\n",
            "activity: Task Estimation\n",
            "prompt: How should I approach task estimation for the team?<|endoftext|>\n",
            "target: Use story points to estimate the complexity. Small tasks might be 1-3 points, medium tasks 5 points, and larger tasks 8 points or more.<|endoftext|>\n",
            "activity: Task Estimation\n",
            "prompt: What's the best way to handle uncertainty during task estimation?<|endoftext|>\n",
            "target: If uncertain, assign a broader range or estimate conservatively. You can also break down the task further to gain clarity on the complexity.<|endoftext|>\n",
            "activity: Sprint Review\n",
            "prompt: What should I focus on for the sprint review?<|endoftext|>\n",
            "target: Highlight the completed features, demonstrate them if possible, and discuss any feedback or unmet goals to help plan for the next sprint.<|endoftext|>\n",
            "activity: Sprint Review\n",
            "prompt: How can I structure my sprint review presentation?<|endoftext|>\n",
            "target: Start with an overview of sprint goals, demonstrate key features completed, discuss any challenges faced, and finish with next steps or improvements.<|endoftext|>\n",
            "activity: User Story Creation\n",
            "prompt: How do I create an effective user story?<|endoftext|>\n",
            "target: Write a user story that describes the who, what, and why of the feature. Example: 'As a user, I want to log in securely so that my data is protected.'<|endoftext|>\n",
            "activity: User Story Creation\n",
            "prompt: What are the essential parts of a user story?<|endoftext|>\n",
            "target: A user story should include a role, goal, and reason. For example: 'As [role], I want [goal] so that [reason].' Add acceptance criteria for clarity.<|endoftext|>\n",
            "activity: Defect Resolution\n",
            "prompt: How should I prioritize defects?<|endoftext|>\n",
            "target: Prioritize defects based on severity and impact on the user. Critical bugs that block functionality should be addressed first.<|endoftext|>\n",
            "activity: Defect Resolution\n",
            "prompt: What should I include in a defect report?<|endoftext|>\n",
            "target: Include a clear description of the issue, steps to reproduce, expected vs. actual results, and any relevant screenshots or logs.<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "\n",
        "# Data collator setup\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "# Training arguments with optimizations\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/gpt2_sprint_model\",\n",
        "    overwrite_output_dir=True,\n",
        "    num_train_epochs=5,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=2,\n",
        "    learning_rate=1e-5,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    logging_dir='/content/logs',\n",
        "    logging_steps=200,\n",
        "    evaluation_strategy=\"no\",\n",
        ")\n",
        "\n",
        "# Trainer setup\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=tokenized_dataset,\n",
        ")\n",
        "\n",
        "# Start training\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "dvZFZWqmgbcV",
        "outputId": "3273ad4b-5eb5-488a-b9fd-5254ecf7d122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:07, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'max_length': 50, 'do_sample': True}\n",
            "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"/content/gpt2_sprint_model\")\n",
        "tokenizer.save_pretrained(\"/content/gpt2_sprint_model\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSTd-dikrm3",
        "outputId": "dfafd7d7-18ee-4f31-d41f-fd33c3c89141"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/gpt2_sprint_model/tokenizer_config.json',\n",
              " '/content/gpt2_sprint_model/special_tokens_map.json',\n",
              " '/content/gpt2_sprint_model/vocab.json',\n",
              " '/content/gpt2_sprint_model/merges.txt',\n",
              " '/content/gpt2_sprint_model/added_tokens.json')"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the trained model\n",
        "model = GPT2LMHeadModel.from_pretrained(\"/content/gpt2_sprint_model\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"/content/gpt2_sprint_model\")\n",
        "\n",
        "# Set up the pipeline for text generation on GPU if available\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)  # use device=0 for GPU\n",
        "\n",
        "# Generate output for a test input\n",
        "input_text = \"Help me plan tasks for the sprint focused on login features.\"\n",
        "output = generator(input_text, max_length=150, num_return_sequences=1, truncation=True)\n",
        "print(output[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4FQeLs6saS4",
        "outputId": "16f0c417-7263-4d4f-8a88-f2bc5858879e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help me plan tasks for the sprint focused on login features.\n",
            "\n",
            "We always need to think in the context of users and we have to have something working well enough for the users that we will need to build functionality for during the sprint. This is an excellent opportunity to build tools to test specific features, such as integration, integration tests, integration docs, integration tests for UI, integration docs for users and users for integration.\n",
            "\n",
            "As a bonus our users will appreciate the ability to see how we are working on integration in our sprint reports too so they can easily provide feedback.\n",
            "\n",
            "Integration Testing\n",
            "\n",
            "In addition to testing to make sure our new features work as intended, we want to provide feedback for integration to our regular user:\n",
            "\n"
          ]
        }
      ]
    }
  ]
}